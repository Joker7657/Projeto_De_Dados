## ðŸŽ¯ Sobre o Projeto

Este projeto implementa um **pipeline completo de Data Engineering**, simulando um ambiente real de anÃ¡lise de dados de vendas. Demonstra competÃªncias essenciais para profissionais de dados:

- **ETL Pipeline**: Extract, Transform, Load com tratamento de dados sujos
- **Data Quality**: ValidaÃ§Ãµes e garantia de qualidade dos dados
- **Data Warehouse**: Modelagem dimensional (Star Schema)
- **Advanced Analytics**: KPIs, RFM, Cohort Analysis, Window Functions
- **Performance**: OtimizaÃ§Ã£o com Ã­ndices estratÃ©gicos

**Caso de Uso**: Sistema de anÃ¡lise de vendas com dados provenientes de mÃºltiplas fontes (APIs, Excel, sistemas legados) que precisam ser consolidados, limpos e estruturados para anÃ¡lise.

---

---

## ðŸ—ï¸ Arquitetura

O projeto segue uma arquitetura em camadas moderna para processamento de dados:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LAYER 1       â”‚     â”‚   LAYER 2       â”‚     â”‚   LAYER 3        â”‚     â”‚   LAYER 4    â”‚
â”‚   RAW DATA      â”‚ --> â”‚   STAGING       â”‚ --> â”‚ DATA WAREHOUSE   â”‚ --> â”‚  ANALYTICS   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Dados brutos  â”‚     â”‚ â€¢ Limpeza       â”‚     â”‚ â€¢ Star Schema    â”‚     â”‚ â€¢ KPIs       â”‚
â”‚ â€¢ Sem tipagem   â”‚     â”‚ â€¢ ValidaÃ§Ã£o     â”‚     â”‚ â€¢ DimensÃµes      â”‚     â”‚ â€¢ RFM        â”‚
â”‚ â€¢ Inconsistente â”‚     â”‚ â€¢ PadronizaÃ§Ã£o  â”‚     â”‚ â€¢ Fatos          â”‚     â”‚ â€¢ Cohorts    â”‚
â”‚ â€¢ Duplicados    â”‚     â”‚ â€¢ ConversÃ£o     â”‚     â”‚ â€¢ Otimizado      â”‚     â”‚ â€¢ Growth     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Fluxo de Dados

1. **RAW**: IngestÃ£o de dados "sujos" em formato TEXT
2. **STAGING**: Limpeza, padronizaÃ§Ã£o e validaÃ§Ã£o
3. **DATA WAREHOUSE**: Modelagem dimensional (Star Schema)
4. **ANALYTICS**: Consultas analÃ­ticas e geraÃ§Ã£o de insights

---

## ðŸ’» Tecnologias

| Tecnologia | VersÃ£o | Uso |
|------------|--------|-----|
| **PostgreSQL** | 15+ | Database principal |
| **SQL** | ANSI SQL | Queries e transformaÃ§Ãµes |
| **Docker** | Latest | ContainerizaÃ§Ã£o (opcional) |

**Conceitos Aplicados:**
- ETL (Extract, Transform, Load)
- Star Schema / Dimensional Modeling
- Window Functions & CTEs
- Data Quality & Governance
- Performance Optimization

---

## ðŸš€ InstalaÃ§Ã£o e ExecuÃ§Ã£o

### PrÃ©-requisitos

- PostgreSQL 12+ instalado
- Acesso ao usuÃ¡rio `postgres`

### OpÃ§Ã£o 1: PostgreSQL Local

```bash
# 1. Criar banco de dados
psql -U postgres -c "CREATE DATABASE advanced_sql;"

# 2. Executar pipeline completo
cd /path/to/project

# Layer 1: RAW
psql -d advanced_sql -f database/schema_raw.sql
psql -d advanced_sql -f database/insert_raw.sql

# Layer 2: STAGING
psql -d advanced_sql -f database/schema_staging.sql
psql -d advanced_sql -f etl/cleaning.sql
psql -d advanced_sql -f etl/data_quality_checks.sql

# Layer 3: DATA WAREHOUSE
psql -d advanced_sql -f database/schema_dw.sql
psql -d advanced_sql -f etl/dw_load.sql
psql -d advanced_sql -f database/indexes.sql

# Layer 4: ANALYTICS
psql -d advanced_sql -f analytics/kpis.sql
psql -d advanced_sql -f analytics/rfm_segmentation.sql
psql -d advanced_sql -f analytics/cohort_analysis.sql
psql -d advanced_sql -f analytics/revenue_growth.sql
psql -d advanced_sql -f analytics/window_functions.sql
```

### OpÃ§Ã£o 2: Docker

```bash
# Iniciar container PostgreSQL
docker run --name postgres-analytics \
  -e POSTGRES_PASSWORD=postgres \
  -p 5432:5432 -d postgres:latest

# Executar scripts
docker exec -i postgres-analytics psql -U postgres -c "CREATE DATABASE advanced_sql;"
docker exec -i postgres-analytics psql -U postgres -d advanced_sql < database/schema_raw.sql
# ... (continuar com demais scripts)
```

---

## ðŸ“ Estrutura do Projeto

```
.
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ schema_raw.sql          # Tabela de dados brutos
â”‚   â”œâ”€â”€ insert_raw.sql          # Dados de exemplo com problemas
â”‚   â”œâ”€â”€ schema_staging.sql      # Tabela intermediÃ¡ria
â”‚   â”œâ”€â”€ schema_dw.sql           # Data Warehouse (Star Schema)
â”‚   â””â”€â”€ indexes.sql             # Ãndices de performance
â”‚
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ cleaning.sql            # Limpeza e transformaÃ§Ã£o
â”‚   â”œâ”€â”€ data_quality_checks.sql # ValidaÃ§Ãµes de qualidade
â”‚   â””â”€â”€ dw_load.sql             # Carga no DW
â”‚
â”œâ”€â”€ analytics/
â”‚   â”œâ”€â”€ kpis.sql                # Indicadores-chave
â”‚   â”œâ”€â”€ rfm_segmentation.sql    # SegmentaÃ§Ã£o RFM
â”‚   â”œâ”€â”€ cohort_analysis.sql     # AnÃ¡lise de cohorts
â”‚   â”œâ”€â”€ revenue_growth.sql      # Crescimento de receita
â”‚   â””â”€â”€ window_functions.sql    # Rankings e anÃ¡lises
â”‚
â””â”€â”€ README.md
```

---

## ðŸ“Š Detalhamento das Camadas

### Layer 1: RAW Data

**Objetivo**: Receber dados brutos sem transformaÃ§Ã£o

**CaracterÃ­sticas:**
- Todos os campos sÃ£o `TEXT`
- Dados propositalmente "sujos" para simular cenÃ¡rio real
- Problemas inclusos: duplicatas, formatos inconsistentes, valores nulos

**Exemplo de problemas:**
```sql
-- Datas em mÃºltiplos formatos
'10-01-2024', '15/02/2024', '2024/02/20', '2024-03-01'

-- InconsistÃªncias
'Completed' vs 'completed'  -- Case mismatch
'rn' vs 'RN' vs 'Sp'        -- PadronizaÃ§Ã£o de estados
NULL em campos obrigatÃ³rios
Registros duplicados (ID 4)
```

---

### Layer 2: STAGING

**Objetivo**: Limpar, validar e padronizar dados

**TransformaÃ§Ãµes:**

1. **RemoÃ§Ã£o de Duplicatas**
   ```sql
   DELETE FROM raw_sales WHERE ctid NOT IN (
     SELECT MIN(ctid) FROM raw_sales 
     GROUP BY sale_id, customer_name, product_name, sale_date
   );
   ```

2. **PadronizaÃ§Ã£o**
   - Status: `LOWER(status)` â†’ 'completed', 'canceled'
   - Estados: `UPPER(state)` â†’ 'RN', 'CE', 'RJ'

3. **ConversÃ£o de Tipos**
   - TEXT â†’ INT, DATE, NUMERIC
   - Tratamento de mÃºltiplos formatos de data com REGEX

4. **ValidaÃ§Ã£o**
   - Remove registros com campos crÃ­ticos NULL
   - Garante integridade referencial

---

### Layer 3: DATA WAREHOUSE

**Objetivo**: Modelagem dimensional otimizada para analytics

**Modelagem Star Schema:**

```
                    dim_date
                      â†“
dim_customers â†’ fact_sales â† dim_products
```

**Tabelas:**

- **dim_customers**: DimensÃ£o de clientes (ID, nome, estado)
- **dim_products**: DimensÃ£o de produtos (ID, nome, categoria)
- **dim_date**: DimensÃ£o temporal (data, ano, mÃªs, trimestre)
- **fact_sales**: Tabela fato com mÃ©tricas (quantidade, valor, status)

**BenefÃ­cios:**
- âš¡ Performance otimizada para queries analÃ­ticas
- ðŸ“Š AgregaÃ§Ãµes multidimensionais simplificadas
- ðŸ”„ FÃ¡cil manutenÃ§Ã£o e evoluÃ§Ã£o
- ðŸ“ˆ CompatÃ­vel com ferramentas de BI (Power BI, Tableau)

---

### Layer 4: ANALYTICS

**Objetivo**: Gerar insights de negÃ³cio

#### 1. KPIs (Key Performance Indicators)
```sql
-- MÃ©tricas essenciais de negÃ³cio
â€¢ Receita Total: SUM(total_value)
â€¢ Ticket MÃ©dio: AVG(total_value)
â€¢ Clientes Ativos: COUNT(DISTINCT customer_id)
â€¢ Taxa de Cancelamento: % de vendas canceladas
```

#### 2. SegmentaÃ§Ã£o RFM
AnÃ¡lise avanÃ§ada de marketing baseada em:
- **Recency**: Dias desde Ãºltima compra
- **Frequency**: NÃºmero de compras
- **Monetary**: Valor total gasto

Usa `NTILE()` para criar quintis (1-5), permitindo segmentaÃ§Ã£o precisa de clientes.

#### 3. Window Functions
```sql
-- Ranking de clientes por gasto
DENSE_RANK() OVER (ORDER BY total_spent DESC)

-- ComparaÃ§Ã£o com perÃ­odo anterior
LAG(revenue) OVER (ORDER BY year, month)
```

#### 4. Cohort Analysis
Agrupa clientes pelo mÃªs da primeira compra e rastreia comportamento ao longo do tempo.

#### 5. Revenue Growth
AnÃ¡lise de crescimento mÃªs a mÃªs com cÃ¡lculo de diferenÃ§a absoluta e percentual.

---

## ðŸŽ¯ Conceitos Aplicados

## ðŸŽ¯ Conceitos Aplicados

| Conceito | ImplementaÃ§Ã£o | Arquivo |
|----------|---------------|---------|
| **ETL Pipeline** | Extract (RAW) â†’ Transform (STAGING) â†’ Load (DW) | `etl/*` |
| **Data Quality** | ValidaÃ§Ãµes, detecÃ§Ã£o de anomalias | `etl/data_quality_checks.sql` |
| **Star Schema** | Modelagem dimensional com fatos e dimensÃµes | `database/schema_dw.sql` |
| **Window Functions** | RANK, LAG, NTILE para anÃ¡lises avanÃ§adas | `analytics/window_functions.sql` |
| **IndexaÃ§Ã£o** | B-tree indexes em foreign keys e filtros | `database/indexes.sql` |
| **CTEs** | Common Table Expressions para legibilidade | `analytics/rfm_segmentation.sql` |
| **Data Normalization** | RemoÃ§Ã£o de duplicatas e padronizaÃ§Ã£o | `etl/cleaning.sql` |

---

## ðŸŽ“ Skills Demonstradas

Este projeto serve como **portfÃ³lio profissional** demonstrando:

```
âœ“ PostgreSQL AvanÃ§ado          âœ“ Star Schema Modeling
âœ“ Pipeline ETL Completo        âœ“ Data Quality & Governance  
âœ“ SQL Analytics AvanÃ§ado       âœ“ Performance Optimization
âœ“ Window Functions & CTEs      âœ“ Business Intelligence
âœ“ Data Transformation          âœ“ Best Practices
```

---

## ðŸ“ˆ Resultados Esperados

ApÃ³s executar o pipeline completo, vocÃª terÃ¡:

- âœ… **6 tabelas** criadas (raw, staging, dim_*, fact_*)
- âœ… **Dados limpos** sem duplicatas ou inconsistÃªncias
- âœ… **5 anÃ¡lises** prontas para uso
- âœ… **Ãndices** otimizados para performance
- âœ… **MÃ©tricas** de qualidade validadas

**Exemplo de output:**
```sql
-- KPIs
Receita Total: R$ 3.660,00
Ticket MÃ©dio: R$ 1.830,00
Clientes Ativos: 1
Taxa de Cancelamento: 0%

-- Revenue Growth
Crescimento mÃªs a mÃªs: +2087.5%
```
